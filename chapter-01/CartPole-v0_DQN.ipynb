{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "encouraging-california",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sharing-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "\n",
    "# Import the desired algorithm from baselines\n",
    "from baselines import deepq\n",
    "\n",
    "def callback(locals, globals):\n",
    "    \"\"\"\n",
    "    Function called at every step with state of the algrithm.\n",
    "    If callback returns true, training stops.\n",
    "    Stop training if average reward exceeds 199.\n",
    "    Time should be greater than 100 and the average of last 100\n",
    "    returns should be >= 199\n",
    "    \"\"\"\n",
    "    is_solved = (\n",
    "        locals[\"t\"] > 100 and sum(locals[\"episode_rewards\"][-101:-1]) / 100 >= 199\n",
    "    )\n",
    "    return is_solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "spectacular-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape is (4,)\n",
      "input shape is (4,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bigal\\anaconda3\\envs\\RLW\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\bigal\\anaconda3\\envs\\RLW\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to C:\\Users\\bigal\\AppData\\Local\\Temp\\openai-2021-03-30-16-37-44-083219\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 98       |\n",
      "| episodes                | 10       |\n",
      "| mean 100 episode reward | 17.8     |\n",
      "| steps                   | 159      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 96       |\n",
      "| episodes                | 20       |\n",
      "| mean 100 episode reward | 19.7     |\n",
      "| steps                   | 374      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 94       |\n",
      "| episodes                | 30       |\n",
      "| mean 100 episode reward | 20.4     |\n",
      "| steps                   | 592      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 92       |\n",
      "| episodes                | 40       |\n",
      "| mean 100 episode reward | 20.4     |\n",
      "| steps                   | 794      |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 90       |\n",
      "| episodes                | 50       |\n",
      "| mean 100 episode reward | 20.4     |\n",
      "| steps                   | 1000     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 87       |\n",
      "| episodes                | 60       |\n",
      "| mean 100 episode reward | 21.1     |\n",
      "| steps                   | 1241     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 85       |\n",
      "| episodes                | 70       |\n",
      "| mean 100 episode reward | 21       |\n",
      "| steps                   | 1448     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 83       |\n",
      "| episodes                | 80       |\n",
      "| mean 100 episode reward | 21.2     |\n",
      "| steps                   | 1676     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 82       |\n",
      "| episodes                | 90       |\n",
      "| mean 100 episode reward | 20.6     |\n",
      "| steps                   | 1836     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 80       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 20.4     |\n",
      "| steps                   | 2019     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 77       |\n",
      "| episodes                | 110      |\n",
      "| mean 100 episode reward | 21.8     |\n",
      "| steps                   | 2343     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 74       |\n",
      "| episodes                | 120      |\n",
      "| mean 100 episode reward | 22.5     |\n",
      "| steps                   | 2627     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 70       |\n",
      "| episodes                | 130      |\n",
      "| mean 100 episode reward | 24.5     |\n",
      "| steps                   | 3039     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 67       |\n",
      "| episodes                | 140      |\n",
      "| mean 100 episode reward | 25.5     |\n",
      "| steps                   | 3344     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 61       |\n",
      "| episodes                | 150      |\n",
      "| mean 100 episode reward | 29.5     |\n",
      "| steps                   | 3948     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 51       |\n",
      "| episodes                | 160      |\n",
      "| mean 100 episode reward | 36.9     |\n",
      "| steps                   | 4934     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 45       |\n",
      "| episodes                | 170      |\n",
      "| mean 100 episode reward | 40.8     |\n",
      "| steps                   | 5532     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 41       |\n",
      "| episodes                | 180      |\n",
      "| mean 100 episode reward | 43.1     |\n",
      "| steps                   | 5985     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 35       |\n",
      "| episodes                | 190      |\n",
      "| mean 100 episode reward | 47.3     |\n",
      "| steps                   | 6570     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 29       |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 51.6     |\n",
      "| steps                   | 7177     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 25       |\n",
      "| episodes                | 210      |\n",
      "| mean 100 episode reward | 52.9     |\n",
      "| steps                   | 7631     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 23       |\n",
      "| episodes                | 220      |\n",
      "| mean 100 episode reward | 52.3     |\n",
      "| steps                   | 7853     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 20       |\n",
      "| episodes                | 230      |\n",
      "| mean 100 episode reward | 50.2     |\n",
      "| steps                   | 8064     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 16       |\n",
      "| episodes                | 240      |\n",
      "| mean 100 episode reward | 51.5     |\n",
      "| steps                   | 8493     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 12       |\n",
      "| episodes                | 250      |\n",
      "| mean 100 episode reward | 49.8     |\n",
      "| steps                   | 8930     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 8        |\n",
      "| episodes                | 260      |\n",
      "| mean 100 episode reward | 43.6     |\n",
      "| steps                   | 9289     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 270      |\n",
      "| mean 100 episode reward | 44.7     |\n",
      "| steps                   | 10005    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 280      |\n",
      "| mean 100 episode reward | 50.8     |\n",
      "| steps                   | 11063    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 290      |\n",
      "| mean 100 episode reward | 55.6     |\n",
      "| steps                   | 12126    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 52.8     |\n",
      "| steps                   | 12459    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 310      |\n",
      "| mean 100 episode reward | 61.2     |\n",
      "| steps                   | 13746    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 320      |\n",
      "| mean 100 episode reward | 72.2     |\n",
      "| steps                   | 15073    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 330      |\n",
      "| mean 100 episode reward | 85.2     |\n",
      "| steps                   | 16583    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 340      |\n",
      "| mean 100 episode reward | 94.3     |\n",
      "| steps                   | 17921    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 350      |\n",
      "| mean 100 episode reward | 96.4     |\n",
      "| steps                   | 18565    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 360      |\n",
      "| mean 100 episode reward | 99.9     |\n",
      "| steps                   | 19275    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 370      |\n",
      "| mean 100 episode reward | 101      |\n",
      "| steps                   | 20086    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 380      |\n",
      "| mean 100 episode reward | 102      |\n",
      "| steps                   | 21284    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 390      |\n",
      "| mean 100 episode reward | 111      |\n",
      "| steps                   | 23256    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 119      |\n",
      "| steps                   | 24336    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 410      |\n",
      "| mean 100 episode reward | 114      |\n",
      "| steps                   | 25147    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 420      |\n",
      "| mean 100 episode reward | 107      |\n",
      "| steps                   | 25762    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 430      |\n",
      "| mean 100 episode reward | 97.1     |\n",
      "| steps                   | 26295    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 440      |\n",
      "| mean 100 episode reward | 93.7     |\n",
      "| steps                   | 27288    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 450      |\n",
      "| mean 100 episode reward | 96.5     |\n",
      "| steps                   | 28215    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 460      |\n",
      "| mean 100 episode reward | 98.3     |\n",
      "| steps                   | 29109    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 470      |\n",
      "| mean 100 episode reward | 99.6     |\n",
      "| steps                   | 30046    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 480      |\n",
      "| mean 100 episode reward | 100      |\n",
      "| steps                   | 31310    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 490      |\n",
      "| mean 100 episode reward | 89.5     |\n",
      "| steps                   | 32208    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 81.4     |\n",
      "| steps                   | 32472    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 510      |\n",
      "| mean 100 episode reward | 85.2     |\n",
      "| steps                   | 33663    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 520      |\n",
      "| mean 100 episode reward | 86.7     |\n",
      "| steps                   | 34429    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 530      |\n",
      "| mean 100 episode reward | 87       |\n",
      "| steps                   | 34992    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 540      |\n",
      "| mean 100 episode reward | 94.4     |\n",
      "| steps                   | 36726    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 550      |\n",
      "| mean 100 episode reward | 100      |\n",
      "| steps                   | 38233    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 560      |\n",
      "| mean 100 episode reward | 111      |\n",
      "| steps                   | 40202    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 570      |\n",
      "| mean 100 episode reward | 121      |\n",
      "| steps                   | 42178    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 580      |\n",
      "| mean 100 episode reward | 123      |\n",
      "| steps                   | 43610    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 590      |\n",
      "| mean 100 episode reward | 126      |\n",
      "| steps                   | 44763    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 600      |\n",
      "| mean 100 episode reward | 130      |\n",
      "| steps                   | 45474    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 610      |\n",
      "| mean 100 episode reward | 124      |\n",
      "| steps                   | 46013    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 620      |\n",
      "| mean 100 episode reward | 118      |\n",
      "| steps                   | 46273    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 630      |\n",
      "| mean 100 episode reward | 115      |\n",
      "| steps                   | 46507    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 640      |\n",
      "| mean 100 episode reward | 102      |\n",
      "| steps                   | 46928    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 650      |\n",
      "| mean 100 episode reward | 97.1     |\n",
      "| steps                   | 47939    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 660      |\n",
      "| mean 100 episode reward | 94       |\n",
      "| steps                   | 49606    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 670      |\n",
      "| mean 100 episode reward | 91.5     |\n",
      "| steps                   | 51332    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 680      |\n",
      "| mean 100 episode reward | 88.3     |\n",
      "| steps                   | 52437    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 690      |\n",
      "| mean 100 episode reward | 83       |\n",
      "| steps                   | 53068    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 700      |\n",
      "| mean 100 episode reward | 78.6     |\n",
      "| steps                   | 53329    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 710      |\n",
      "| mean 100 episode reward | 75.9     |\n",
      "| steps                   | 53601    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 720      |\n",
      "| mean 100 episode reward | 75.4     |\n",
      "| steps                   | 53817    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 730      |\n",
      "| mean 100 episode reward | 75.7     |\n",
      "| steps                   | 54079    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 740      |\n",
      "| mean 100 episode reward | 73.9     |\n",
      "| steps                   | 54322    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 750      |\n",
      "| mean 100 episode reward | 67.7     |\n",
      "| steps                   | 54712    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 760      |\n",
      "| mean 100 episode reward | 57       |\n",
      "| steps                   | 55305    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 770      |\n",
      "| mean 100 episode reward | 49.7     |\n",
      "| steps                   | 56303    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 780      |\n",
      "| mean 100 episode reward | 49.7     |\n",
      "| steps                   | 57405    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 790      |\n",
      "| mean 100 episode reward | 55.8     |\n",
      "| steps                   | 58653    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 800      |\n",
      "| mean 100 episode reward | 73       |\n",
      "| steps                   | 60624    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 810      |\n",
      "| mean 100 episode reward | 90.2     |\n",
      "| steps                   | 62624    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 820      |\n",
      "| mean 100 episode reward | 108      |\n",
      "| steps                   | 64624    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 830      |\n",
      "| mean 100 episode reward | 125      |\n",
      "| steps                   | 66624    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 840      |\n",
      "| mean 100 episode reward | 137      |\n",
      "| steps                   | 68067    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 850      |\n",
      "| mean 100 episode reward | 148      |\n",
      "| steps                   | 69556    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 860      |\n",
      "| mean 100 episode reward | 152      |\n",
      "| steps                   | 70527    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 870      |\n",
      "| mean 100 episode reward | 150      |\n",
      "| steps                   | 71335    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 880      |\n",
      "| mean 100 episode reward | 152      |\n",
      "| steps                   | 72590    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 890      |\n",
      "| mean 100 episode reward | 153      |\n",
      "| steps                   | 73929    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 900      |\n",
      "| mean 100 episode reward | 141      |\n",
      "| steps                   | 74710    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 910      |\n",
      "| mean 100 episode reward | 132      |\n",
      "| steps                   | 75789    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 920      |\n",
      "| mean 100 episode reward | 129      |\n",
      "| steps                   | 77490    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 930      |\n",
      "| mean 100 episode reward | 127      |\n",
      "| steps                   | 79305    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 940      |\n",
      "| mean 100 episode reward | 128      |\n",
      "| steps                   | 80918    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 950      |\n",
      "| mean 100 episode reward | 131      |\n",
      "| steps                   | 82660    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 960      |\n",
      "| mean 100 episode reward | 138      |\n",
      "| steps                   | 84305    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 970      |\n",
      "| mean 100 episode reward | 148      |\n",
      "| steps                   | 86081    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 980      |\n",
      "| mean 100 episode reward | 150      |\n",
      "| steps                   | 87633    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 990      |\n",
      "| mean 100 episode reward | 151      |\n",
      "| steps                   | 89035    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1000     |\n",
      "| mean 100 episode reward | 152      |\n",
      "| steps                   | 89923    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1010     |\n",
      "| mean 100 episode reward | 152      |\n",
      "| steps                   | 90947    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1020     |\n",
      "| mean 100 episode reward | 146      |\n",
      "| steps                   | 92141    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1030     |\n",
      "| mean 100 episode reward | 141      |\n",
      "| steps                   | 93420    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1040     |\n",
      "| mean 100 episode reward | 137      |\n",
      "| steps                   | 94648    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1050     |\n",
      "| mean 100 episode reward | 128      |\n",
      "| steps                   | 95472    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1060     |\n",
      "| mean 100 episode reward | 120      |\n",
      "| steps                   | 96271    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1070     |\n",
      "| mean 100 episode reward | 113      |\n",
      "| steps                   | 97389    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 1080     |\n",
      "| mean 100 episode reward | 111      |\n",
      "| steps                   | 98703    |\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "\"\"\"\n",
    "Prepare learning parameters: network and learning rate\n",
    "The policy is a multi-layer perceptron\n",
    "\"\"\"\n",
    "network = \"mlp\"\n",
    "# Set learning rate of the algorithm\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\"\"\"\n",
    "Launch learning on this environment using DQN\n",
    "Ignore the exploration parameter for now\n",
    "\"\"\"\n",
    "actor = deepq.learn(env,\n",
    "                   network=network,\n",
    "                   lr=learning_rate,\n",
    "                   total_timesteps=100000,\n",
    "                   buffer_size=50000,\n",
    "                   exploration_fraction=0.1,\n",
    "                   exploration_final_eps=0.02,\n",
    "                   print_freq=10,\n",
    "                   callback=callback,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "private-sodium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to cartpole_model.pkl\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DEEPQ' object has no attribute 'save_act'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c36de2288b56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Saving model to cartpole_model.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cartpole_model.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DEEPQ' object has no attribute 'save_act'"
     ]
    }
   ],
   "source": [
    "print(\"Saving model to cartpole_model.pkl\")\n",
    "actor.save_act(\"cartpole_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-discussion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-production",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-dutch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
